{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shared_functions_wlp_wls as shared\n",
    "import scipy.integrate\n",
    "from halotools.empirical_models import PrebuiltHodModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SURVEY = 'SDSS'\n",
    "if (SURVEY=='SDSS'):\n",
    "    import params as pa\n",
    "elif (SURVEY=='LSST_DESI'):\n",
    "    import params_LSST_DESI as pa\n",
    "else:\n",
    "    print \"We don't have support for that survey yet; exiting.\"\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: compare our $<N_{\\rm sat}>$ vs $M_h$ and $<N_{\\rm cen}>$ vs $M_h$ for Zu & Mandelbaum 2015 to the PreBuilt model in HaloTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a halo mass range\n",
    "#lgMh = np.linspace(9.5, 15.5, 100)\n",
    "#Mh = 10**(lgMh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Jan 8: implementing the fact that there is a typo in equation 19 of Zu and Mandelbaum (10^ vs exp)\n",
    "# Check how old and new relationships look for sanity check\n",
    "Ms = np.logspace(8, 12, 5000)\n",
    "m = Ms / pa.Mso\n",
    "Mh_old = pa.M1 * m**(pa.beta) * np.exp( m**pa.delta / (1. + m**(-pa.gamma)) - 0.5)\n",
    "Mh_new = pa.M1 * m**(pa.beta) * 10**( m**pa.delta / (1. + m**(-pa.gamma)) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(Ms, Mh_old, 'b', label='old')\n",
    "plt.hold(True)\n",
    "plt.loglog(Ms, Mh_new, 'm', label='new')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(Mh_old, Ms, 'b', label='old')\n",
    "plt.hold(True)\n",
    "plt.loglog(Mh_new, Ms, 'm', label='new')\n",
    "plt.xlim(10**10, 10**16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracket_term = m**pa.delta / (1. + m**(-pa.gamma)) - 0.5\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(Ms, bracket_term)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SDSS we get $M_*^{\\rm low} = 6.8 \\times 10^{9}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mslow = 6.8*10**9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get $<N_{\\rm sat}>$ and $<N_{\\rm cen}>$ from our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsat_us = shared.get_Nsat_Zu(Mh, Mslow, 'tot', 'SDSS')\n",
    "Ncen_us = shared.get_Ncen_Zu(Mh, Mslow, 'SDSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and get the same from halotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrebuiltHodModelFactory('zu_mandelbaum15', threshold = np.log10(Mslow), prim_haloprop_key = 'halo_m200m')\n",
    "Nsat_HT = model.mean_occupation_satellites(prim_haloprop=Mh)\n",
    "Ncen_HT = model.mean_occupation_centrals(prim_haloprop=Mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(lgMh, Nsat_us, 'g', label='$N_{\\\\rm sat}$, me')\n",
    "plt.hold(True)\n",
    "plt.semilogy(lgMh, Nsat_HT, 'm', label='$N_{\\\\rm sat}$, HT')\n",
    "plt.ylim(0.01, 10000)\n",
    "plt.ylabel('$N_{\\\\rm sat}$')\n",
    "plt.xlabel('$M_h / h$')\n",
    "plt.legend(loc=2)\n",
    "#plt.show()\n",
    "plt.savefig('./plots/Nsat_me_vs_halotools_SDSSshapes.pdf')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lgMh, Ncen_us, 'g', label='$N_{\\\\rm cen}$, me')\n",
    "plt.hold(True)\n",
    "plt.plot(lgMh, Ncen_HT, 'm', label='$N_{\\\\rm cen}$, HT')\n",
    "#plt.ylim(0.01, 100)\n",
    "plt.ylabel('$N_{\\\\rm cen}$')\n",
    "plt.xlabel('$M_h / h$')\n",
    "plt.legend(loc=2)\n",
    "#plt.show()\n",
    "plt.savefig('./plots/Ncen_me_vs_halotools_SDSSshapes.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are two high compared to the figure. Also, some of them are overlapping. What's wrong here?\n",
    "Let's try to reproduce the right hand side of Figure 8, the Stellar - Halo mass relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Msvec = np.logspace(np.log10(7*10**8), np.log10(6*10**11), 100)\n",
    "#Mh_out = shared.fSHMR_inverse(Msvec, 'SDSS')\n",
    "\n",
    "#plt.figure()\n",
    "#plt.loglog(Mh_out, Msvec)\n",
    "#plt.ylabel('$M_{*}$')\n",
    "#plt.xlabel('$M_h$')\n",
    "#plt.xlim(10**11, 3*10**15)\n",
    "#plt.ylim(7*10**8, 6*10**11)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is wrong too. Okay, let's try explicitly typing out the relation as in the paper rather than calling the funciton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's because I'm not accounting for the scatter. There is actually a formula in Ying's paper which provides a fit to the correct thing that we CAN directly invert (I think), not accounting for scatter. Let's try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Msvec = np.logspace(np.log10(2*10**8), np.log10(10**13), 100)\n",
    "Mh_get = shared.Mh_atfixed_Ms(Msvec)\n",
    "lgMh_fit = np.log10(Mh_get)\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(Msvec, 10**lgMh_fit)\n",
    "plt.ylabel('$M_{h}$')\n",
    "plt.xlabel('$M_*$')\n",
    "plt.ylim(5*10**10, 3*10**15)\n",
    "plt.xlim(2*10**8, 10**12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, but what we actually want is $M_*(M_h)$. We know that at a fixed halo mass, the star mass has a log-normal scatter, and we know this scatter. So we can get, for each $M_h$, a mean $lnM_*(Mh)$ (from the relation of equation 19) and a series of other $ln M_*$ values drawn from a lognormal distribution aroumd this. The average of these $ln(M_*)$ value is then the mean value to associate with M_h. Try this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define an extended stellar vector for integrating over\n",
    "Msvec = np.logspace(np.log10(2*10**8), np.log10(10**13), 100)\n",
    "lnMstar = np.log(Msvec)\n",
    "\n",
    "# For each halo mass\n",
    "lgMh = np.linspace(11.5, 14., 100)\n",
    "Mh = 10**(lgMh)\n",
    "fshmr = np.zeros(len(lgMh))\n",
    "for mi in range(0,len(lgMh)):\n",
    "    lnMstar_mean = np.log(shared.get_fSHMR(Mh[mi], 'SDSS'))\n",
    "    siglnM = shared.get_sigMs(Mh[mi], 'SDSS')\n",
    "    # Define the lognormal distribution of M*\n",
    "    p = 1. / (np.sqrt(2 * np.pi) * siglnM) * np.exp(-(lnMstar - lnMstar_mean)**2 / (2. * siglnM**2))\n",
    "    #norm = np.sum(p)\n",
    "    #p_normed = p / norm\n",
    "    # Now sample from this distribution a bunch of lnM* values\n",
    "    #lnMslist= np.random.choice(np.log(Msvec), p=p_normed, size = 10000)\n",
    "    # Now get their mean\n",
    "    lnMs_avg = scipy.integrate.simps(lnMstar * p, lnMstar)\n",
    "    #lnMs_avg = np.mean(lnMslist)\n",
    "    fshmr[mi] = np.exp(lnMs_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue I am having now is the following.\n",
    "\n",
    "I know $f_{\\rm SHMR}(M_h) = exp(<ln(M_*(M_h))>)$\n",
    "\n",
    "I know that $M_*$ is lognormally distributed at fixed halo mass, and I know its scatter.\n",
    "\n",
    "But, how do I get its mean? This seems like a circular argument. I am trying to integrate:\n",
    "$\\int p(M_*,M_h) ln(M_*) d ln(M_*)$ \n",
    "to get the mean value $<ln(M_*(M_h))>$. But to get $p(M_*, M_h)$ in the first place, I require this mean value. How do I get out of this circle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(Mh, fshmr)\n",
    "plt.ylabel('$M_{*}$')\n",
    "plt.xlabel('$M_h$')\n",
    "plt.xlim(10**11, 3*10**15)\n",
    "plt.ylim(7*10**8, 6*10**11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
