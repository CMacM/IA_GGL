{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the large scale galaxy bias as implied by the HOD models we use for each source and lens sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/halo_table_cache.py:12: UserWarning: Some of the functionality of the HaloTableCache classrequires h5py to be installed.\n",
      "  warn(\"Some of the functionality of the HaloTableCache class\"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/user_supplied_ptcl_catalog.py:13: UserWarning: Most of the functionality of the sim_manager sub-package requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda\n",
      "  warn(\"Most of the functionality of the sim_manager \"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/download_manager.py:39: UserWarning: Some of the functionality of the DownloadManager requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda\n",
      "  warn(\"Some of the functionality of the DownloadManager requires h5py to be installed,\\n\"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/cached_halo_catalog.py:15: UserWarning: Most of the functionality of the sim_manager sub-package requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda. \n",
      "  warn(\"Most of the functionality of the \"\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "#% matplotlib inline\n",
    "import numpy as np; import scipy.integrate; import scipy.interpolate; import matplotlib.pyplot as plt\n",
    "import pyccl as ccl; import shared_functions_wlp_wls as shared; import shared_functions_setup as setup\n",
    "from halotools.empirical_models import PrebuiltHodModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the survey\n",
    "survey = 'LSST_DESI'\n",
    "if (survey == 'SDSS'):\n",
    "    import params as pa\n",
    "elif (survey == 'LSST_DESI'):\n",
    "    import params_LSST_DESI as pa\n",
    "    \n",
    "# Also set whether we are looking at lenses or sources\n",
    "gals = 'lens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize the cosmology\n",
    "#OmM = pa.OmC_s + pa.OmB_s; OmB=pa.OmB_s; h0 = pa.HH0_s / 100.; sigma80=pa.sigma8_s; n_s0 = pa.n_s_s;\n",
    "OmM = pa.OmC + pa.OmB; OmB=pa.OmB; h0 = pa.HH0 / 100.; As0=pa.A_s; n_s0 = pa.n_s;\n",
    "\n",
    "#p = ccl.Parameters(Omega_c = OmM-OmB, Omega_b = OmB, h = h0, sigma8=sigma80, n_s=n_s0)\n",
    "p = ccl.Parameters(Omega_c = OmM-OmB, Omega_b = OmB, h = h0, A_s = As0, n_s=n_s0)\n",
    "cosmo = ccl.Cosmology(p)\n",
    "\n",
    "#chi = ccl.background.comoving_radial_distance(cosmo, 1./(1.+0.4))\n",
    "#print \"chi=\", chi\n",
    "\n",
    "rho_crit = 3. * 10**10 * pa.mperMpc / (8. * np.pi * pa.Gnewt * pa.Msun)  # Msol h^2 / Mpc^3, for use with M in Msol / h (comoving distances)\n",
    "rho_m = (OmM) * rho_crit # units of Msol h^2 / Mpc^3 (comoving distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the appropriate redshift distribution\n",
    "if (gals=='lens'):\n",
    "    z = np.linspace(pa.zLmin, pa.zLmax, 100)\n",
    "    dNdz = setup.get_dNdzL(z, survey)\n",
    "if (gals =='src'):\n",
    "    z, dNdz_unnormed = setup.get_NofZ_unnormed(pa.dNdzpar_fid, pa.dNdztype, pa.zsmin, pa.zsmax, 500, survey)\n",
    "    norm = scipy.integrate.simps(dNdz_unnormed, z)\n",
    "    dNdz = dNdz_unnormed / norm\n",
    " \n",
    "# Get the window function of sources x lenses (this is the redshift range we care about)\n",
    "#(z, dNdz) = shared.window(survey)    \n",
    "  \n",
    "# Get the halo mass function and halo bias\n",
    "Mhvec = np.logspace(9.,16,30) # In units Msol / h\n",
    "HMF = np.zeros((len(Mhvec), len(z)))\n",
    "bh = np.zeros((len(Mhvec), len(z)))\n",
    "for zi in range(0,len(z)):\n",
    "    HMF[:,zi] = ccl.massfunction.massfunc(cosmo, Mhvec / h0, 1./ (1. + z[zi]), odelta=200.) / (h0**3)\n",
    "    bh[:,zi] = ccl.massfunction.halo_bias(cosmo, Mhvec / h0, 1./(1.+z[zi]), odelta=200.)\n",
    "\n",
    "#HMF= ccl.massfunction.massfunc(cosmo, Mhvec / (pa.HH0/100.), 1./ (1. + z), odelta=200.) / (pa.HH0/100.)**3\n",
    "#bh = ccl.massfunction.halo_bias(cosmo, Mhvec / (pa.HH0/100.), 1./(1.+z), odelta=200.)\n",
    "    \n",
    "# Integrate bh over z just for ploting \n",
    "#bh_M = np.zeros(len(Mhvec))\n",
    "#for mi in range(0,len(Mhvec)):\n",
    "#    bh_M[mi] = scipy.integrate.simps(bh[mi, :] * dNdz, z)\n",
    "    \n",
    "#plt.figure()\n",
    "#plt.loglog(Mhvec, bh_M)\n",
    "#plt.xlim(10**9,10**15)\n",
    "#plt.ylim(0.1, 10)\n",
    "#plt.xlabel('Halo mass, $M_\\odot / h$')\n",
    "#plt.ylabel('$b_h$')\n",
    "#plt.title(\"Halo bias, SDSS src dNdz\")\n",
    "#plt.show()\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('./plots/halobias_SDSS_src.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get y(k,M) (the fourier transformed profile)\n",
    "logkmin = -6; kpts =40000; logkmax = 5; \n",
    "kvec_FT = np.logspace(logkmin, logkmax, kpts)\n",
    "# Actually we will use a downsampled version of this:\n",
    "k = np.logspace(np.log10(kvec_FT[0]), np.log10(kvec_FT[-1]), 40)\n",
    "y = shared.gety_ldm(Mhvec, k, survey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the linear matter power spectrum from CCL to multiply through\n",
    "Pklin = np.zeros((len(k), len(z)))\n",
    "for zi in range(0,len(z)):\n",
    "    # CCL uses units without little-h. Convert to little-h units.\n",
    "    Pklin[:, zi] = ccl.power.linear_matter_power(cosmo, k * h0, 1. / (1. + z[zi])) * h0**3\n",
    "\n",
    "# We now have all the ingredients we require to get the 2-halo matter power spectrum \n",
    "# We don't use this, I'm just checking we get something reasonable at this intermediate step\n",
    "#twoh_fact = np.zeros((len(k), len(z)))\n",
    "#for ki in range(0,len(k)):\n",
    "#    for zi in range(0,len(z)):\n",
    "#        twoh_fact[ki, zi] = scipy.integrate.simps( Mhvec / rho_m * HMF[:,zi] * bh[:, zi] * y[ki, :], np.log10(Mhvec / (pa.HH0_s / 100.)))    \n",
    "\n",
    "#Pk_2h = Pklin * (twoh_fact)**2\n",
    "\n",
    "# Integrate over z\n",
    "#Pk_2h_avgz = np.zeros(len(k))\n",
    "#Pklin_avgz = np.zeros(len(k))\n",
    "#for ki in range(0,len(k)):\n",
    "#    Pk_2h_avgz[ki] = scipy.integrate.simps(dNdz * Pk_2h[ki,:], z)\n",
    "#    Pklin_avgz[ki] = scipy.integrate.simps(dNdz * Pklin[ki,:], z)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.loglog(k, k**3 * Pk_2h_avgz / 2. / np.pi**2, 'b')\n",
    "#plt.hold(True)\n",
    "#plt.loglog(k, k**3 * Pklin_avgz  / 2. / np.pi**2, 'm')\n",
    "#plt.xlim(0.05,30)\n",
    "#plt.ylim(0.01, 100)\n",
    "#plt.show()\n",
    "\n",
    "# This isn't exactly 1 at large scales because we aren't integrating down to all the masses where halos exist.\n",
    "# This shouldn't matter in the end for galaxy bias because those mass halos won't host galaxies.\n",
    "# When we get the galaxy bias we will compare to halofit ie the same as Pklin_avgz on large scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, we want to convert this to a 2-halo galaxy power spectrum using the various HOD's we use.\n",
    "\n",
    "if (gals=='src'):\n",
    "#    # We need Mstarlow for the Zu & Mandelbaum halo model\n",
    "    tot_nsrc = shared.vol_dens(pa.fsky, pa.N_shapes, survey)\n",
    "    Mstarlow = shared.get_Mstar_low(survey, tot_nsrc)\n",
    "    #print \"tot_nsrc=\", tot_nsrc\n",
    "    #print \"Mstarlow=\", Mstarlow\n",
    "    \n",
    "# Get occupation numbers as a function of mass\n",
    "if (survey == 'SDSS'):\n",
    "    if (gals=='lens'):\n",
    "        Ncen = shared.get_Ncen_Reid(Mhvec, survey)  # Reid & Spergel\n",
    "        Nsat = shared.get_Nsat_Reid(Mhvec, survey)  # Reid & Spergel \n",
    "    elif (gals=='src'):\n",
    "        # Let's use HaloTools and see what happens\n",
    "        #model = PrebuiltHodModelFactory('zu_mandelbaum15', threshold = np.log10(Mstarlow), prim_haloprop_key = 'halo_m200m')\n",
    "        #Nsat = model.mean_occupation_satellites(prim_haloprop=Mhvec)\n",
    "        #Ncen = model.mean_occupation_centrals(prim_haloprop=Mhvec)\n",
    "        Ncen = shared.get_Ncen_Zu(Mhvec, Mstarlow, survey)  \t# Zu & Mandelbaum 2015\n",
    "        Nsat_wlens = shared.get_Nsat_Zu(Mhvec, Mstarlow, 'with_lens', survey)  # Zu & Mandelbaum 2015\n",
    "        Nsat_tot = shared.get_Nsat_Zu(Mhvec, Mstarlow, 'tot', survey)  # Zu & Mandelbaum 2015\n",
    "elif (survey== 'LSST_DESI'):\n",
    "    if (gals =='lens'):\n",
    "        Ncen = shared.get_Ncen_More(Mhvec, survey) # CMASS\n",
    "        Nsat = shared.get_Nsat_More(Mhvec, survey) # CMASS \n",
    "    elif(gals=='src'):\n",
    "        Ncen = shared.get_Ncen_Zu(Mhvec, Mstarlow, survey)  \t# Zu & Mandelbaum 2015\n",
    "        Nsat_wlens = shared.get_Nsat_Zu(Mhvec, Mstarlow, 'with_lens', survey)  # Zu & Mandelbaum 2015\n",
    "        Nsat_tot = shared.get_Nsat_Zu(Mhvec, Mstarlow, 'tot', survey)  # Zu & Mandelbaum 2015\n",
    "\n",
    "# Combine to get the total occupation at mass M\n",
    "N_tot= Ncen + Nsat\n",
    "\n",
    "# Get satelite fraction integrated over mass\n",
    "Nsat_int_ofz = np.zeros(len(z))\n",
    "Ntot_int_ofz = np.zeros(len(z))\n",
    "for zi in range(0,len(z)):\n",
    "    Nsat_int_ofz[zi] = scipy.integrate.simps(Nsat * HMF[:,zi], np.log10(Mhvec / h0))\n",
    "    Ntot_int_ofz[zi] = scipy.integrate.simps(N_tot * HMF[:,zi], np.log10(Mhvec / h0))\n",
    "    \n",
    "Nsat_int = scipy.integrate.simps(Nsat_int_ofz * dNdz, z)\n",
    "Ntot_int = scipy.integrate.simps(Ntot_int_ofz * dNdz, z)\n",
    "#Nsat_int = scipy.integrate.simps(Nsat * HMF, np.log10(Mhvec / (pa.HH0/100.)))\n",
    "#Ntot_int= scipy.integrate.simps(N_tot * HMF, np.log10(Mhvec / (pa.HH0/100.)))\n",
    "satfrac = Nsat_int / Ntot_int\n",
    "print \"sat frac=\", satfrac\n",
    "\n",
    "# Get the numerator of the halo bias of each population\n",
    "bcen_of_z = np.zeros(len(z))\n",
    "bsat_of_z = np.zeros(len(z))\n",
    "btot_of_z = np.zeros(len(z))\n",
    "for zi in range(0,len(z)):\n",
    "    bcen_of_z[zi] = scipy.integrate.simps(bh[:, zi] * HMF[:,zi] * Ncen, np.log10(Mhvec / h0))\n",
    "    bsat_of_z[zi] = scipy.integrate.simps(bh[:, zi] * HMF[:,zi] * Nsat, np.log10(Mhvec / h0))\n",
    "    btot_of_z[zi] = scipy.integrate.simps(bh[:,zi] * HMF[:,zi] * N_tot, np.log10(Mhvec / h0))\n",
    "\n",
    "bcen_int = scipy.integrate.simps(bcen_of_z * dNdz, z)\n",
    "bsat_int = scipy.integrate.simps(bsat_of_z * dNdz, z)\n",
    "btot_int = scipy.integrate.simps(btot_of_z * dNdz, z)\n",
    "                                \n",
    "#bcen_int = scipy.integrate.simps(bh * HMF * Ncen, np.log10(Mhvec / (pa.HH0/100.)))\n",
    "#bsat_int = scipy.integrate.simps(bh * HMF * Nsat, np.log10(Mhvec / (pa.HH0/100.)))    \n",
    "#btot_int = scipy.integrate.simps(bh * HMF * N_tot, np.log10(Mhvec / (pa.HH0/100.)))\n",
    "    \n",
    "# Integrate over the halo mass function to get total number density \n",
    "nbar = np.zeros(len(z))\n",
    "nbar_sat = np.zeros(len(z))\n",
    "nbar_cen = np.zeros(len(z))\n",
    "for zi in range(0,len(z)):\n",
    "    nbar[zi] = scipy.integrate.simps(HMF[:,zi] * N_tot, np.log10(Mhvec / h0))\n",
    "    nbar_sat[zi]= scipy.integrate.simps(HMF[:,zi] * Nsat, np.log10(Mhvec / h0))\n",
    "    nbar_cen[zi]= scipy.integrate.simps(HMF[:,zi] * Ncen, np.log10(Mhvec / h0))\n",
    "                                \n",
    "#nbar_int= scipy.integrate.simps(HMF * N_tot, np.log10(Mhvec / ((pa.HH0/100.))))\n",
    "#nbar_sat_int= scipy.integrate.simps(HMF * Nsat, np.log10(Mhvec / ((pa.HH0/100.))))\n",
    "#nbar_cen_int= scipy.integrate.simps(HMF * Ncen, np.log10(Mhvec / ((pa.HH0/100.))))   \n",
    "print \"N_tot=\", N_tot\n",
    "print \"nbar=\", nbar\n",
    "    \n",
    "nbar_int = scipy.integrate.simps(nbar *dNdz, z)\n",
    "nbar_cen_int = scipy.integrate.simps(nbar_cen * dNdz, z)\n",
    "nbar_sat_int = scipy.integrate.simps(nbar_sat*dNdz, z)\n",
    "\n",
    "print \"halo bias, centrals=\", bcen_int / nbar_cen_int\n",
    "print \"halo bias, satelites =\", bsat_int / nbar_sat_int\n",
    "print \"halo bias, all =\", btot_int / nbar_int\n",
    "print \"nbar int=\", nbar_int\n",
    "\n",
    "#plt.figure()\n",
    "#plt.semilogx(Mhvec, Ncen, 'mo')\n",
    "#plt.xlim(10**12,10**17)\n",
    "#plt.title('$N_{\\\\rm cen}$, SDSS sources')\n",
    "#plt.ylabel('$N_{\\\\rm cen}$')\n",
    "#plt.xlabel('$M_h$, $M_\\odot / h$')\n",
    "#plt.ylim(10**(-3), 10**(3))\n",
    "#plt.show()\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('./plots/Ncen_SDSS_src.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the galaxy-galaxy 2-halo term\n",
    "\n",
    "twoh_gg = np.zeros((len(k), len(z)))\n",
    "for ki in range(0,len(k)):\n",
    "    for zi in range(0,len(z)):\n",
    "        twoh_gg[ki,zi] = scipy.integrate.simps(HMF[:,zi] * bh[:,zi] * y[ki, :] * N_tot, np.log10(Mhvec/h0)) / nbar[zi]\n",
    "       \n",
    "#twoh_gg = np.zeros(len(k))\n",
    "#for ki in range(0,len(k)):\n",
    "#    twoh_gg[ki] = scipy.integrate.simps(HMF * bh* y[ki, :] * N_tot, np.log10(Mhvec/(pa.HH0_s/100))) / nbar_int\n",
    "\n",
    "P_2h_gg = np.zeros((len(k), len(z)))\n",
    "for ki in range(0,len(k)):\n",
    "    for zi in range(0,len(z)):\n",
    "        P_2h_gg[ki, zi] = twoh_gg[ki, zi]**2 * Pklin[ki,zi]\n",
    "\n",
    "# Integrate over z\n",
    "P_2h_gg_avgz = np.zeros(len(k))\n",
    "Pklin_avgz = np.zeros(len(k))\n",
    "for ki in range(0,len(k)):\n",
    "    P_2h_gg_avgz[ki] = scipy.integrate.simps(dNdz * P_2h_gg[ki,:], z)\n",
    "    Pklin_avgz[ki] = scipy.integrate.simps(dNdz * Pklin[ki, :], z)\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(k,P_2h_gg_avgz,  'b')\n",
    "plt.hold(True)\n",
    "plt.loglog(k, Pklin_avgz, 'm')\n",
    "plt.xlim(0.0001,30)\n",
    "plt.ylim(0.01, 10**7)\n",
    "plt.show()\n",
    "\n",
    "np.sqrt(P_2h_gg_avgz / Pklin_avgz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now use this to get the scale-dependent bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
