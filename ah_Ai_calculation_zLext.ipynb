{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the value of ah from luminosity scaling, using methodology as in Krause et al. 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a function for the comoving distance\n",
    "\n",
    "def com(z_, OmC, OmB, HH0, Nnu):\n",
    "    \"\"\" Gets the comoving distance in units of Mpc/h at a given redshift, z_ (assuming the cosmology defined in the params file). \"\"\"\n",
    "    \n",
    "    OmR\t=\t2.47*10**(-5)/(HH0/100.)**2\n",
    "    OmN\t=\tNnu*(7./8.)*(4./11.)**(4./3.)*OmR\n",
    "    OmL = 1. - OmC - OmB - OmR - OmN\n",
    "    c=2.99792458*10**(8)\n",
    "    H0\t=\t10**(5)/c\n",
    "    \n",
    "    def chi_int(z):\n",
    "        return 1. / (H0 * ( (OmC+OmB)*(1+z)**3 + OmL + (OmR+OmN) * (1+z)**4 )**(0.5))\n",
    "\n",
    "    if hasattr(z_, \"__len__\"):\n",
    "        chi=np.zeros((len(z_)))\n",
    "        for zi in range(0,len(z_)):\n",
    "            #print \"zi in com=\", zi\n",
    "            chi[zi] = scipy.integrate.quad(chi_int,0,z_[zi])[0]\n",
    "    else:\n",
    "        chi = scipy.integrate.quad(chi_int, 0, z_)[0]\n",
    "\n",
    "    return chi\n",
    "\n",
    "\n",
    "def get_dNdzL(zvec, survey):\n",
    "    \"\"\" Imports the lens redshift distribution from file, normalizes, interpolates, and outputs at the z vector that's passed.\"\"\"\n",
    "\n",
    "    if (survey == 'SDSS'):\n",
    "        import params as pa\n",
    "    elif (survey == 'LSST_DESI'):\n",
    "        import params_LSST_DESI as pa\n",
    "    else:\n",
    "        print \"We don't have support for that survey yet; exiting.\"\n",
    "        exit()\n",
    "    \n",
    "    z, dNdz = np.loadtxt('./txtfiles/'+pa.dNdzL_file, unpack=True)\n",
    "\n",
    "    interpolation = scipy.interpolate.interp1d(z, dNdz)\n",
    "\n",
    "    # Create a well-sampled redshift vector to make sure we can get the normalization without numerical problems\n",
    "    z_highres = np.linspace(z[0], z[-1], 1000)\n",
    "\n",
    "    dNdz_getnorm = interpolation(z_highres)\n",
    "\n",
    "    norm = scipy.integrate.simps(dNdz_getnorm, z_highres)\n",
    "\n",
    "    if ((zvec[0]>=z[0]) and (zvec[-1]<=z[-1])):\n",
    "        dNdz_return = interpolation(zvec)\n",
    "    else:\n",
    "        print \"You have asked for dN/dzl at redshifts out of the known range.\"\n",
    "        exit()\n",
    "\n",
    "    return dNdz_return / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the Schechter luminosity function parameters from Krause et al. 2015\n",
    "\n",
    "mlim_1 = 22.; mlim_2 = 27.5; \n",
    "Mp = -22.\n",
    "Lp = 10.**(-0.4*(Mp-Mp))\n",
    "\n",
    "# Power law parameters\n",
    "alpha_h = 0.081; beta_h = 2.1\n",
    "A_0 = 4.9; beta = 1.30;\n",
    "\n",
    "# We are using parameters from Krause et al. 2015, red galaxies\n",
    "#Mr_s = -20.34; Q = 1.8; alpha = -0.57; phi_0 = 1.1 * 10**(-2); P = -1.2 # This set is all from GAMA\n",
    "Mr_s = -20.34; Q = 1.2; alpha = -0.57; phi_0 = 1.1 * 10**(-2); P = -1.15 # This set uses Q & P scaled from DEEP2\n",
    "\n",
    "\n",
    "# Cosmological parameters\n",
    "Nnu\t=\t3.046    # Massless neutrinos\n",
    "HH0 = 67.26 \n",
    "OmR\t=\t2.47*10**(-5)/(HH0/100.)**2\n",
    "OmN\t=\tNnu*(7./8.)*(4./11.)**(4./3.)*OmR\n",
    "OmB\t=\t0.02222/(HH0/100.)**2 \n",
    "OmC\t=\t0.1199/(HH0/100.)**2 \n",
    "OmM=  OmB+OmC\n",
    "A_s\t=\t2.2 * 10**(-9)\n",
    "n_s\t=\t0.9652\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute phi*(z) and M*(z) / L*(z), where z is the lens redshift \n",
    "zL1 = np.linspace(0.16, 0.36, 200); zL2 = np.linspace(0.025, 1.175, 200)\n",
    "\n",
    "phi_s_1 = phi_0 * 10**(0.4 * P*zL1); \n",
    "phi_s_2 = phi_0 * 10**(0.4 * P*zL2); \n",
    "\n",
    "Ms_1 = Mr_s - Q * ( zL1 - 0.1 ); Ms_2 = Mr_s - Q * ( zL2 - 0.1)\n",
    "Ls_1 = 10.**(-0.4 *(Ms_1-Mp)); Ls_2 = 10.**(-0.4 *(Ms_2-Mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the k correction and EC correction from Poggianti (assuming elliptical galaxies)\n",
    "(z_k, kcorr, x,x,x) = np.loadtxt('./txtfiles/kcorr.dat', unpack=True)\n",
    "(z_e, ecorr, x,x,x) = np.loadtxt('./txtfiles/ecorr.dat', unpack=True)\n",
    "\n",
    "kcorr_interp = scipy.interpolate.interp1d(z_k, kcorr)\n",
    "ecorr_interp = scipy.interpolate.interp1d(z_e, ecorr)\n",
    "\n",
    "kcorr_1 = kcorr_interp(zL1)\n",
    "ecorr_1 = ecorr_interp(zL1)\n",
    "kcorr_2 = kcorr_interp(zL2)\n",
    "ecorr_2 = ecorr_interp(zL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the absolute magnitude that corresponds to the limiting apparent magnitude\n",
    "dl_1 = com(zL1, OmC, OmB, HH0, Nnu) * (1. + zL1)\n",
    "dl_2 = com(zL2, OmC, OmB, HH0, Nnu) * (1. + zL2)\n",
    "\n",
    "Mlim_1 = mlim_1 - (5. * np.log10(dl_1) + 25. + kcorr_1 + ecorr_1); Llim_1 = 10.**(-0.4 * (Mlim_1-Mp))\n",
    "#print \"Mlim 1=\", Mlim_1\n",
    "Mlim_2 = mlim_2 - (5. * np.log10(dl_2) + 25. + kcorr_2 + ecorr_2); Llim_2 = 10.**(-0.4 * (Mlim_2-Mp))\n",
    "#print \"Mlim 2=\", Mlim_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the luminosity vectors over which to integrate\n",
    "# For each case, there will be a list of these, one for each redshift,\n",
    "# because the limiting values if z-dependent\n",
    "\n",
    "L_1 = [0] * len(zL1)\n",
    "for zi in range(0,len(zL1)):\n",
    "    L_1[zi] = scipy.logspace(np.log10(Llim_1[zi]), 2, 1000)\n",
    "L_2 = [0]*len(zL2)\n",
    "for zi in range(0,len(zL2)):\n",
    "    L_2[zi] = scipy.logspace(np.log10(Llim_2[zi]), 2, 1000)\n",
    "\n",
    "# Now get phi(L,z), where this exists for each z because the lenghts of the L vectors are different.\n",
    "phi_func_1 = [0]*len(zL1)\n",
    "for zi in range(0,len(zL1)):\n",
    "    phi_func_1[zi]= np.zeros(len(L_1[zi]))\n",
    "    for li in range(0,len(L_1[zi])):\n",
    "        phi_func_1[zi][li] = phi_s_1[zi] * (L_1[zi][li] / Ls_1[zi]) ** (alpha) * np.exp(- L_1[zi][li] / Ls_1[zi])\n",
    "\n",
    "phi_func_2 = [0]*len(zL2)\n",
    "for zi in range(0,len(zL2)):\n",
    "    phi_func_2[zi]= np.zeros(len(L_2[zi]))\n",
    "    for li in range(0,len(L_2[zi])):\n",
    "        phi_func_2[zi][li] = phi_s_2[zi] * (L_2[zi][li] / Ls_2[zi]) ** (alpha) * np.exp(- L_2[zi][li] / Ls_2[zi])        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the numerator and denom (norm) of the required averages in luminosity, still as functions of zL\n",
    "\n",
    "norm_1 = np.zeros(len(zL1)); num_ah_1 = np.zeros(len(zL1)); num_Ai_1 = np.zeros(len(zL1)) \n",
    "avgL_1 = np.zeros(len(zL1))\n",
    "for zi in range(len(zL1)):\n",
    "    norm_1[zi] = scipy.integrate.simps(phi_func_1[zi], L_1[zi])\n",
    "    num_ah_1[zi] = scipy.integrate.simps(phi_func_1[zi] * alpha_h * (L_1[zi] / Lp)**(beta_h), L_1[zi])\n",
    "    num_Ai_1[zi] = scipy.integrate.simps(phi_func_1[zi] * A_0 * (L_1[zi] / Lp)**(beta), L_1[zi])\n",
    "    avgL_1[zi] = scipy.integrate.simps(phi_func_1[zi] * L_1[zi] / Lp, L_1[zi])\n",
    "    \n",
    "norm_2 = np.zeros(len(zL2)); num_ah_2 = np.zeros(len(zL2)); num_Ai_2 = np.zeros(len(zL2))\n",
    "avgL_2=np.zeros(len(zL2))\n",
    "for zi in range(len(zL2)):\n",
    "    norm_2[zi] = scipy.integrate.simps(phi_func_2[zi], L_2[zi])\n",
    "    num_ah_2[zi] = scipy.integrate.simps(phi_func_2[zi] * alpha_h * (L_2[zi] / Lp)**(beta_h), L_2[zi])\n",
    "    num_Ai_2[zi] = scipy.integrate.simps(phi_func_2[zi] * A_0 * (L_2[zi] / Lp)**(beta), L_2[zi])\n",
    "    avgL_2[zi] = scipy.integrate.simps(phi_func_2[zi] * L_2[zi] / Lp, L_2[zi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################\n",
      "For SDSS:\n",
      "ah = 0.00508024109555 Ai= 0.600388324123 Average L= 0.175014469581\n",
      "###################################################\n",
      "For LSST + DESI\n",
      "ah = 0.0125376550036 Ai= 0.928226346412 Average L= 0.230261229935\n"
     ]
    }
   ],
   "source": [
    "# Get the lens galaxy distributions, over which we will integrate z\n",
    "dNdzl_1 = get_dNdzL(zL1, 'SDSS')\n",
    "dNdzl_2 = get_dNdzL(zL2, 'LSST_DESI')\n",
    "\n",
    "# Test what happens when we revert to a zeff by using a narrow Gaussian\n",
    "#sig_small = 0.01\n",
    "#dNdzl_1 = 1./np.sqrt(2. * np.pi) / sig_small * np.exp(- (zL1 - 0.28)**2 / (2. * sig_small**2))\n",
    "#dNdzl_2 = 1./np.sqrt(2. * np.pi) / sig_small * np.exp(- (zL2 - 0.77)**2 / (2. * sig_small**2))\n",
    "\n",
    "# Get the final amplitude values and the average luminosities for each case:\n",
    "ah_1 = scipy.integrate.simps(num_ah_1 / norm_1 * dNdzl_1, zL1)\n",
    "Ai_1 = scipy.integrate.simps(num_Ai_1 / norm_1 * dNdzl_1, zL1)\n",
    "avgL_1 = scipy.integrate.simps(avgL_1 / norm_1 * dNdzl_1, zL1)\n",
    "ah_2 = scipy.integrate.simps(num_ah_2 / norm_2 * dNdzl_2, zL2)\n",
    "Ai_2 = scipy.integrate.simps(num_Ai_2 / norm_2 * dNdzl_2, zL2)\n",
    "avgL_2 = scipy.integrate.simps(avgL_2 / norm_2 * dNdzl_2, zL2)\n",
    "\n",
    "print \"###################################################\"\n",
    "print \"For SDSS:\"\n",
    "print \"ah =\", ah_1, \"Ai=\", Ai_1, \"Average L=\", avgL_1\n",
    "print \"###################################################\"\n",
    "print \"For LSST + DESI\"\n",
    "print \"ah =\", ah_2, \"Ai=\", Ai_2, \"Average L=\", avgL_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
