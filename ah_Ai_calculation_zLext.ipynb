{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the value of ah from luminosity scaling, using methodology as in Krause et al. 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a function for the comoving distance\n",
    "\n",
    "def com(z_, OmC, OmB, HH0, Nnu):\n",
    "    \"\"\" Gets the comoving distance in units of Mpc/h at a given redshift, z_ (assuming the cosmology defined in the params file). \"\"\"\n",
    "    \n",
    "    OmR\t=\t2.47*10**(-5)/(HH0/100.)**2\n",
    "    OmN\t=\tNnu*(7./8.)*(4./11.)**(4./3.)*OmR\n",
    "    OmL = 1. - OmC - OmB - OmR - OmN\n",
    "    c=2.99792458*10**(8)\n",
    "    H0\t=\t10**(5)/c\n",
    "    \n",
    "    def chi_int(z):\n",
    "        return 1. / (H0 * ( (OmC+OmB)*(1+z)**3 + OmL + (OmR+OmN) * (1+z)**4 )**(0.5))\n",
    "\n",
    "    if hasattr(z_, \"__len__\"):\n",
    "        chi=np.zeros((len(z_)))\n",
    "        for zi in range(0,len(z_)):\n",
    "            #print \"zi in com=\", zi\n",
    "            chi[zi] = scipy.integrate.quad(chi_int,0,z_[zi])[0]\n",
    "    else:\n",
    "        chi = scipy.integrate.quad(chi_int, 0, z_)[0]\n",
    "\n",
    "    return chi\n",
    "\n",
    "\n",
    "def get_dNdzL(zvec, survey):\n",
    "    \"\"\" Imports the lens redshift distribution from file, normalizes, interpolates, and outputs at the z vector that's passed.\"\"\"\n",
    "\n",
    "    if (survey == 'SDSS'):\n",
    "        import params as pa\n",
    "    elif (survey == 'LSST_DESI'):\n",
    "        import params_LSST_DESI as pa\n",
    "    else:\n",
    "        print \"We don't have support for that survey yet; exiting.\"\n",
    "        exit()\n",
    "    \n",
    "    z, dNdz = np.loadtxt('./txtfiles/'+pa.dNdzL_file, unpack=True)\n",
    "\n",
    "    interpolation = scipy.interpolate.interp1d(z, dNdz)\n",
    "\n",
    "    # Create a well-sampled redshift vector to make sure we can get the normalization without numerical problems\n",
    "    z_highres = np.linspace(z[0], z[-1], 1000)\n",
    "\n",
    "    dNdz_getnorm = interpolation(z_highres)\n",
    "\n",
    "    norm = scipy.integrate.simps(dNdz_getnorm, z_highres)\n",
    "\n",
    "    if ((zvec[0]>=z[0]) and (zvec[-1]<=z[-1])):\n",
    "        dNdz_return = interpolation(zvec)\n",
    "    else:\n",
    "        print \"You have asked for dN/dzl at redshifts out of the known range.\"\n",
    "        exit()\n",
    "\n",
    "    return dNdz_return / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the Schechter luminosity function parameters from Krause et al. 2015\n",
    "\n",
    "mlim_1 = 22.; mlim_2 = 27.5; \n",
    "Mp = -22.\n",
    "Lp = 10.**(-0.4*(Mp-Mp))\n",
    "\n",
    "# Power law parameters\n",
    "alpha_h = 0.081; beta_h = 2.1\n",
    "A_0 = 4.9; beta = 1.30;\n",
    "\n",
    "# We are using parameters from Krause et al. 2015, red galaxies\n",
    "#Mr_s = -20.34; Q = 1.8; alpha = -0.57; phi_0 = 1.1 * 10**(-2); P = -1.2 # This set is all from GAMA\n",
    "Mr_s = -20.34; Q = 1.2; alpha = -0.57; phi_0 = 1.1 * 10**(-2); P = -1.15 # This set uses Q & P scaled from DEEP2\n",
    "\n",
    "\n",
    "# Cosmological parameters\n",
    "Nnu\t=\t3.046    # Massless neutrinos\n",
    "HH0 = 67.26 \n",
    "OmR\t=\t2.47*10**(-5)/(HH0/100.)**2\n",
    "OmN\t=\tNnu*(7./8.)*(4./11.)**(4./3.)*OmR\n",
    "OmB\t=\t0.02222/(HH0/100.)**2 \n",
    "OmC\t=\t0.1199/(HH0/100.)**2 \n",
    "OmM=  OmB+OmC\n",
    "A_s\t=\t2.2 * 10**(-9)\n",
    "n_s\t=\t0.9652\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute phi*(z) and M*(z) / L*(z), where z is the lens redshift \n",
    "zL1 = np.linspace(0.16, 0.36, 200); zL2 = np.linspace(0.025, 1.175, 200)\n",
    "\n",
    "phi_s_1 = phi_0 * 10**(0.4 * P*zL1); \n",
    "phi_s_2 = phi_0 * 10**(0.4 * P*zL2); \n",
    "\n",
    "Ms_1 = Mr_s - Q * ( zL1 - 0.1 ); Ms_2 = Mr_s - Q * ( zL2 - 0.1)\n",
    "Ls_1 = 10.**(-0.4 *(Ms_1-Mp)); Ls_2 = 10.**(-0.4 *(Ms_2-Mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the k correction and EC correction from Poggianti (assuming elliptical galaxies)\n",
    "(z_k, kcorr, x,x,x) = np.loadtxt('./txtfiles/kcorr.dat', unpack=True)\n",
    "(z_e, ecorr, x,x,x) = np.loadtxt('./txtfiles/ecorr.dat', unpack=True)\n",
    "\n",
    "kcorr_interp = scipy.interpolate.interp1d(z_k, kcorr)\n",
    "ecorr_interp = scipy.interpolate.interp1d(z_e, ecorr)\n",
    "\n",
    "kcorr_1 = kcorr_interp(zL1)\n",
    "ecorr_1 = ecorr_interp(zL1)\n",
    "kcorr_2 = kcorr_interp(zL2)\n",
    "ecorr_2 = ecorr_interp(zL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdss= 1001.06847705\n",
      "lsst= 3327.99294587\n",
      "Mlim 1= [-16.62541756 -16.64106588 -16.65662773 -16.67210417 -16.68749623\n",
      " -16.70280492 -16.71803123 -16.73317613 -16.7482406  -16.76322556\n",
      " -16.77813194 -16.79296065 -16.80771258 -16.82238861 -16.8369896\n",
      " -16.85151639 -16.86596982 -16.88035071 -16.89465986 -16.90889806\n",
      " -16.92306608 -16.9371647  -16.95119466 -16.96515671 -16.97905156\n",
      " -16.99287994 -17.00664255 -17.02034009 -17.03397322 -17.04754263\n",
      " -17.06104898 -17.07449291 -17.08787506 -17.10119607 -17.11445654\n",
      " -17.12765711 -17.14079835 -17.15388087 -17.16690525 -17.17987205\n",
      " -17.19268638 -17.20506236 -17.21738243 -17.22964715 -17.24185704\n",
      " -17.25401263 -17.26611444 -17.27816297 -17.29015873 -17.30210222\n",
      " -17.31399391 -17.3258343  -17.33762385 -17.34936304 -17.36105232\n",
      " -17.37269215 -17.38428297 -17.39582524 -17.40731937 -17.41876582\n",
      " -17.43016498 -17.4415173  -17.45282317 -17.46408301 -17.47529722\n",
      " -17.48646619 -17.49759032 -17.50866998 -17.51970557 -17.53069745\n",
      " -17.541646   -17.55255159 -17.56341456 -17.5742353  -17.58501413\n",
      " -17.59575142 -17.6064475  -17.61710271 -17.62771739 -17.63829187\n",
      " -17.64888678 -17.65953259 -17.67013916 -17.68070681 -17.69123585\n",
      " -17.70172658 -17.71217932 -17.72259436 -17.73297199 -17.7433125\n",
      " -17.75361619 -17.76388335 -17.77411424 -17.78430916 -17.79446837\n",
      " -17.80459214 -17.81468076 -17.82473448 -17.83475356 -17.84473827\n",
      " -17.85468885 -17.86460557 -17.87448868 -17.88433842 -17.89415504\n",
      " -17.90393878 -17.91368988 -17.92340858 -17.9330951  -17.94274969\n",
      " -17.95237258 -17.96196398 -17.97152412 -17.98105323 -17.99055152\n",
      " -18.00001922 -18.00945652 -18.01886366 -18.02824083 -18.03758825\n",
      " -18.04684581 -18.05603383 -18.06519271 -18.07432263 -18.08342381\n",
      " -18.09249644 -18.1015407  -18.11055679 -18.1195449  -18.12850521\n",
      " -18.13743792 -18.1463432  -18.15522123 -18.16407219 -18.17289627\n",
      " -18.18169364 -18.19046446 -18.19920892 -18.20792718 -18.21661942\n",
      " -18.22528579 -18.23392648 -18.24254163 -18.25113141 -18.25969598\n",
      " -18.26823551 -18.27675014 -18.28524004 -18.29370536 -18.30214626\n",
      " -18.31056287 -18.31895536 -18.32732388 -18.33566856 -18.34398956\n",
      " -18.35228703 -18.36056109 -18.3688119  -18.3770396  -18.38524432\n",
      " -18.39340611 -18.40154017 -18.40965167 -18.41774073 -18.4258075\n",
      " -18.43385211 -18.44187467 -18.44987533 -18.45785422 -18.46581145\n",
      " -18.47374715 -18.48166146 -18.48955449 -18.49742636 -18.50527721\n",
      " -18.51310713 -18.52091627 -18.52870473 -18.53647263 -18.54422009\n",
      " -18.55194722 -18.55965414 -18.56734096 -18.57500779 -18.58265475\n",
      " -18.59028194 -18.59788947 -18.60547746 -18.613046   -18.62059521\n",
      " -18.62812519 -18.63563605 -18.64312789 -18.65060081 -18.65805491\n",
      " -18.6654903  -18.67290708 -18.68030534 -18.68768519 -18.69504673]\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute magnitude that corresponds to the limiting apparent magnitude\n",
    "dl_1 = com(zL1, OmC, OmB, HH0, Nnu) * (1. + zL1)\n",
    "dl_2 = com(zL2, OmC, OmB, HH0, Nnu) * (1. + zL2)\n",
    "\n",
    "print \"sdss=\", com(0.28, OmC, OmB, HH0, Nnu) * (1. + 0.28)\n",
    "print \"lsst=\", com(0.77, OmC, OmB, HH0, Nnu) * (1. + 0.77)\n",
    "\n",
    "Mlim_1 = mlim_1 - (5. * np.log10(dl_1) + 25. + kcorr_1 + ecorr_1); Llim_1 = 10.**(-0.4 * (Mlim_1-Mp))\n",
    "print \"Mlim 1=\", Mlim_1\n",
    "Mlim_2 = mlim_2 - (5. * np.log10(dl_2) + 25. + kcorr_2 + ecorr_2); Llim_2 = 10.**(-0.4 * (Mlim_2-Mp))\n",
    "#print \"Mlim 2=\", Mlim_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the luminosity vectors over which to integrate\n",
    "# For each case, there will be a list of these, one for each redshift,\n",
    "# because the limiting values if z-dependent\n",
    "\n",
    "L_1 = [0] * len(zL1)\n",
    "for zi in range(0,len(zL1)):\n",
    "    L_1[zi] = scipy.logspace(np.log10(Llim_1[zi]), 2, 1000)\n",
    "L_2 = [0]*len(zL2)\n",
    "for zi in range(0,len(zL2)):\n",
    "    L_2[zi] = scipy.logspace(np.log10(Llim_2[zi]), 2, 1000)\n",
    "\n",
    "# Now get phi(L,z), where this exists for each z because the lenghts of the L vectors are different.\n",
    "phi_func_1 = [0]*len(zL1)\n",
    "for zi in range(0,len(zL1)):\n",
    "    phi_func_1[zi]= np.zeros(len(L_1[zi]))\n",
    "    for li in range(0,len(L_1[zi])):\n",
    "        phi_func_1[zi][li] = phi_s_1[zi] * (L_1[zi][li] / Ls_1[zi]) ** (alpha) * np.exp(- L_1[zi][li] / Ls_1[zi])\n",
    "\n",
    "phi_func_2 = [0]*len(zL2)\n",
    "for zi in range(0,len(zL2)):\n",
    "    phi_func_2[zi]= np.zeros(len(L_2[zi]))\n",
    "    for li in range(0,len(L_2[zi])):\n",
    "        phi_func_2[zi][li] = phi_s_2[zi] * (L_2[zi][li] / Ls_2[zi]) ** (alpha) * np.exp(- L_2[zi][li] / Ls_2[zi])        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the numerator and denom (norm) of the required averages in luminosity, still as functions of zL\n",
    "\n",
    "norm_1 = np.zeros(len(zL1)); num_ah_1 = np.zeros(len(zL1)); num_Ai_1 = np.zeros(len(zL1)) \n",
    "avgL_1 = np.zeros(len(zL1))\n",
    "for zi in range(len(zL1)):\n",
    "    norm_1[zi] = scipy.integrate.simps(phi_func_1[zi], L_1[zi])\n",
    "    num_ah_1[zi] = scipy.integrate.simps(phi_func_1[zi] * alpha_h * (L_1[zi] / Lp)**(beta_h), L_1[zi])\n",
    "    num_Ai_1[zi] = scipy.integrate.simps(phi_func_1[zi] * A_0 * (L_1[zi] / Lp)**(beta), L_1[zi])\n",
    "    avgL_1[zi] = scipy.integrate.simps(phi_func_1[zi] * L_1[zi] / Lp, L_1[zi])\n",
    "    \n",
    "norm_2 = np.zeros(len(zL2)); num_ah_2 = np.zeros(len(zL2)); num_Ai_2 = np.zeros(len(zL2))\n",
    "avgL_2=np.zeros(len(zL2))\n",
    "for zi in range(len(zL2)):\n",
    "    norm_2[zi] = scipy.integrate.simps(phi_func_2[zi], L_2[zi])\n",
    "    num_ah_2[zi] = scipy.integrate.simps(phi_func_2[zi] * alpha_h * (L_2[zi] / Lp)**(beta_h), L_2[zi])\n",
    "    num_Ai_2[zi] = scipy.integrate.simps(phi_func_2[zi] * A_0 * (L_2[zi] / Lp)**(beta), L_2[zi])\n",
    "    avgL_2[zi] = scipy.integrate.simps(phi_func_2[zi] * L_2[zi] / Lp, L_2[zi])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################\n",
      "For SDSS:\n",
      "ah = 0.00508024109555 Ai= 0.600388324123 Average L= 0.175014469581\n",
      "###################################################\n",
      "For LSST + DESI\n",
      "ah = 0.0125376550036 Ai= 0.928226346412 Average L= 0.230261229935\n"
     ]
    }
   ],
   "source": [
    "# Get the lens galaxy distributions, over which we will integrate z\n",
    "dNdzl_1 = get_dNdzL(zL1, 'SDSS')\n",
    "dNdzl_2 = get_dNdzL(zL2, 'LSST_DESI')\n",
    "\n",
    "# Test what happens when we revert to a zeff by using a narrow Gaussian\n",
    "#sig_small = 0.01\n",
    "#dNdzl_1 = 1./np.sqrt(2. * np.pi) / sig_small * np.exp(- (zL1 - 0.28)**2 / (2. * sig_small**2))\n",
    "#dNdzl_2 = 1./np.sqrt(2. * np.pi) / sig_small * np.exp(- (zL2 - 0.77)**2 / (2. * sig_small**2))\n",
    "\n",
    "# Get the final amplitude values and the average luminosities for each case:\n",
    "ah_1 = scipy.integrate.simps(num_ah_1 / norm_1 * dNdzl_1, zL1)\n",
    "Ai_1 = scipy.integrate.simps(num_Ai_1 / norm_1 * dNdzl_1, zL1)\n",
    "avgL_1 = scipy.integrate.simps(avgL_1 / norm_1 * dNdzl_1, zL1)\n",
    "ah_2 = scipy.integrate.simps(num_ah_2 / norm_2 * dNdzl_2, zL2)\n",
    "Ai_2 = scipy.integrate.simps(num_Ai_2 / norm_2 * dNdzl_2, zL2)\n",
    "avgL_2 = scipy.integrate.simps(avgL_2 / norm_2 * dNdzl_2, zL2)\n",
    "\n",
    "print \"###################################################\"\n",
    "print \"For SDSS:\"\n",
    "print \"ah =\", ah_1, \"Ai=\", Ai_1, \"Average L=\", avgL_1\n",
    "print \"###################################################\"\n",
    "print \"For LSST + DESI\"\n",
    "print \"ah =\", ah_2, \"Ai=\", Ai_2, \"Average L=\", avgL_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
