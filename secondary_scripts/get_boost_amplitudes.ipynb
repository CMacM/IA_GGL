{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import scipy.interpolate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_NofZ_unnormed(dNdzpar, dNdztype, z):\n",
    "    \"\"\" Returns the dNdz of the sources as a function of spec-z.\"\"\"\n",
    "\n",
    "    #z = scipy.linspace(z_min+0.0001, z_max, zpts)\n",
    "\n",
    "    if (dNdztype == 'Nakajima'):\n",
    "        # dNdz takes form like in Nakajima et al. 2011 equation 3\n",
    "        a = dNdzpar[0]\n",
    "        zs = dNdzpar[1]\n",
    "        nofz_ = (z / zs)**(a-1) * np.exp( -0.5 * (z / zs)**2)\n",
    "    elif (dNdztype == 'Smail'):\n",
    "        # dNdz take form like in Smail et al. 1994\n",
    "        alpha = dNdzpar[0]\n",
    "        z0 = dNdzpar[1]\n",
    "        beta = dNdzpar[2]\n",
    "        nofz_ = z**alpha * np.exp( - (z / z0)**beta)\n",
    "    else:\n",
    "        print \"dNdz type \"+str(dNdztype)+\" not yet supported; exiting.\"\n",
    "        exit()\n",
    "\n",
    "    return nofz_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_z(z_ph, z_sp, pzpar, pztype):\n",
    "    \"\"\" Returns the probability of finding a photometric redshift z_ph given that the true redshift is z_sp. \"\"\"\n",
    "    \n",
    "    if (pztype == 'Gaussian'):\n",
    "        sigz = pzpar[0]\n",
    "        p_z_ = np.exp(-(z_ph - z_sp)**2 / (2.*(sigz*(1.+z_sp))**2)) / (np.sqrt(2.*np.pi)*(sigz*(1.+z_sp)))\n",
    "    else:\n",
    "        print \"Photo-z probability distribution \"+str(pztype)+\" not yet supported; exiting.\"\n",
    "        exit()\n",
    "    \n",
    "    return p_z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def com(z_, OmC, OmB, HH0, Nnu):\n",
    "    \"\"\" Gets the comoving distance in units of Mpc/h at a given redshift, z_. \"\"\"\n",
    "    \n",
    "    OmR\t=\t2.47*10**(-5)/(HH0/100.)**2\n",
    "    OmN\t=\tNnu*(7./8.)*(4./11.)**(4./3.)*OmR\n",
    "    OmL = 1. - OmC - OmB - OmR - OmN\n",
    "    c=2.99792458*10**(8)\n",
    "    H0\t=\t10**(5)/c\n",
    "    \n",
    "    def chi_int(z):\n",
    "        return 1. / (H0 * ( (OmC+OmB)*(1+z)**3 + OmL + (OmR+OmN) * (1+z)**4 )**(0.5))\n",
    "\n",
    "    if hasattr(z_, \"__len__\"):\n",
    "        chi=np.zeros((len(z_)))\n",
    "        for zi in range(0,len(z_)):\n",
    "            #print \"zi in com=\", zi\n",
    "            chi[zi] = scipy.integrate.quad(chi_int,0,z_[zi])[0]\n",
    "    else:\n",
    "        chi = scipy.integrate.quad(chi_int, 0, z_)[0]\n",
    "\n",
    "    return chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_interpof_com(OmC, OmB, HH0, Nnu):\n",
    "    \"\"\" Returns an interpolating function which can give z as a function of comoving distance. \"\"\"\n",
    "\n",
    "    z_vec = scipy.linspace(0., 10., 10000) # This hardcodes that we don't care about anything over z=100.\n",
    "\n",
    "    com_vec = com(z_vec, OmC, OmB, HH0, Nnu)\n",
    "\n",
    "    z_of_com = scipy.interpolate.interp1d(com_vec, z_vec)\n",
    "    com_of_z =  scipy.interpolate.interp1d(z_vec, com_vec)\n",
    "\n",
    "    return\t(z_of_com, com_of_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_e(z_s_):\n",
    "    \"\"\" Returns a value for the model for the per-galaxy noise as a function of source redshift\"\"\"\n",
    "\n",
    "    if (survey=='SDSS'):\n",
    "\n",
    "        if hasattr(z_s_, \"__len__\"):\n",
    "            sig_e = 2. / S_to_N * np.ones(len(z_s_))\n",
    "        else:\n",
    "            sig_e = 2. / S_to_N\n",
    "\n",
    "    elif(survey=='LSST_DESI'):\n",
    "        if hasattr(z_s_, \"__len__\"):\n",
    "            sig_e = a_sm / SN_med * ( 1. + (b_sm / R_med)**c_sm) * np.ones(len(z_s_))\n",
    "        else:\n",
    "            sig_e = a_sm / SN_med * ( 1. + (b_sm / R_med)**c_sm) \n",
    "\n",
    "    return sig_e\n",
    "\n",
    "def get_SigmaC_inv(z_s_, z_l_):\n",
    "    \"\"\" Returns the theoretical value of 1/Sigma_c, (Sigma_c = the critcial surface mass density) \"\"\"\n",
    "\n",
    "    com_s = chi_of_z(z_s_) \n",
    "    com_l = chi_of_z(z_l_) \n",
    "\n",
    "    # Get scale factors for converting between angular-diameter and comoving distances.\n",
    "    a_l = 1. / (z_l_ + 1.)\n",
    "    a_s = 1. / (z_s_ + 1.)\n",
    "    \n",
    "    D_s = a_s * com_s # Angular diameter source distance.\n",
    "    D_l = a_l * com_l # Angular diameter lens distance\n",
    "    D_ls = (D_s - D_l) \n",
    "        \n",
    "    # Units are pc^2 / (h Msun), comoving\n",
    "    Sigma_c_inv = 4. * np.pi * (Gnewt * Msun) * (10**12 / c**2) / mperMpc *   D_l * D_ls * (1 + z_l_)**2 / D_s\n",
    "\n",
    "    if hasattr(z_s_, \"__len__\"):\n",
    "        for i in range(0,len(z_s_)):\n",
    "            if(z_s_[i]<=z_l_):\n",
    "                Sigma_c_inv[i] = 0.\n",
    "    else:\n",
    "        if (z_s_<=z_l_):\n",
    "            Sigam_c_inv = 0.\n",
    "\n",
    "    return Sigma_c_inv\n",
    "\n",
    "\n",
    "def weights(e_rms, z_, z_l_):\n",
    "\n",
    "    \"\"\" Returns the inverse variance weights as a function of redshift. \"\"\"\n",
    "\n",
    "    SigC_t_inv = get_SigmaC_inv(z_, z_l_)\n",
    "\n",
    "    weights = SigC_t_inv**2/(sigma_e(z_)**2 + e_rms**2 * np.ones(len(z_)))\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up interpolating functions for z(chi) and chi(z)\n",
    "(z_of_chi, chi_of_z) = z_interpof_com(0.2, 0.05, 70., 3.046)\n",
    "\n",
    "# Constants / conversions\n",
    "mperMpc = 3.0856776*10**22\n",
    "Msun = 1.989*10**30 # in kg\n",
    "Gnewt = 6.67408*10**(-11)\n",
    "c=2.99792458*10**(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "zeff = 0.77\n",
    "pztype = 'Gaussian'; pzpar = [0.05]\n",
    "dNdztype='Smail'; dNdzpar =  [1.24, 0.51, 1.01]\n",
    "rp_fix = 1.0\n",
    "zsmax = 6.0\n",
    "\n",
    "zphmin = 0.0\n",
    "zphmax = 7.0\n",
    "deltaz = 0.57\n",
    "close_cut = 100\n",
    "erms = 0.18\n",
    "\n",
    "zPi_min = 0.001\n",
    "zPi_max = 6.0\n",
    "\n",
    "survey = 'LSST_DESI'\n",
    "#S_to_N = 15.\n",
    "a_sm  = 1.58\n",
    "b_sm  = 5.03\n",
    "c_sm  = 0.39\n",
    "SN_med= 11.8\n",
    "R_med = 1.63\n",
    "\n",
    "b_l = 3.57\n",
    "b_s = 2.05\n",
    "\n",
    "# Import the correlation function, from CAMB w/ halofit + FFTlog\n",
    "(r, xi_2h) = np.loadtxt('../txtfiles/xi_z='+str(zeff)+'.txt', unpack=True)\n",
    "xi_2h = b_l* b_s * xi_2h\n",
    "\n",
    "# Import the 1-halo term as computed in our code\n",
    "#(r_1h, xi_1h) = np.loadtxt('../txtfiles/xi_gg_1halo_'+survey+'.txt', unpack=True)\n",
    "#xi_1h_interp = scipy.interpolate.interp1d(r_1h,xi_1h)\n",
    "#xi_1h = xi_1h_interp(r)\n",
    "xi = xi_2h #xi_1h + xi_2h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1945.32426314\n",
      "z_Pi= [  1.02755176e-03   1.05553393e-03   1.08351610e-03 ...,   5.99947919e+00\n",
      "   5.99973958e+00   6.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Get the comoving distance associated to the lens redshift\n",
    "chi_eff = com(zeff, 0.2, 0.05, 70., 3.046)\n",
    "\n",
    "# Figure out the min and max value of the * positive * part of the vector of projected distances\n",
    "if (min(r)>rp_fix):\n",
    "    minPiPos = np.sqrt(min(r)**2 - rp_fix**2)\n",
    "else:\n",
    "    minPiPos = 0.\n",
    "#if (max(r)<com(zsmax, 0.2, 0.05, 70., 3.046)):\n",
    "#    maxPiPos = np.sqrt(max(r)**2 - rp_fix**2)\n",
    "#else:\n",
    "#    maxPiPos = chi_of_z(zsmax)-chi_eff\n",
    "\n",
    "maxPiPos = chi_of_z(zPi_max) - chi_eff\n",
    "\n",
    "Pi_pos = scipy.linspace(minPiPos, maxPiPos, 50000)\n",
    "    \n",
    "# Pi can be positive or negative, so now flip this and include the negative values, but only down to z=0\n",
    "# And avoid including multiple of the same values - this messes up some integration routines.\n",
    "Pi_pos_vec = list(Pi_pos)[1:]\n",
    "Pi_pos_vec.reverse()\n",
    "index_cut = next(j[0] for j in enumerate(Pi_pos_vec) if j[1]<=(chi_eff-chi_of_z(zPi_min)))\n",
    "print chi_of_z(zPi_min)+chi_eff\n",
    "Pi = np.append(-np.asarray(Pi_pos_vec[index_cut:]), Pi_pos)\n",
    "\n",
    "# Get the correlation function in terms of Pi at rp = 1\n",
    "xi_interp_r = scipy.interpolate.interp1d(r, xi)\n",
    "xi_ofPi = xi_interp_r(np.sqrt(rp_fix**2 + Pi**2))\n",
    "\n",
    "# Get the vector of com dist values associated to Pi values:\n",
    "com_Pi = chi_eff + Pi\n",
    "\n",
    "# Get the associated z's\n",
    "z_Pi = z_of_chi(com_Pi)\n",
    "\n",
    "print \"z_Pi=\", z_Pi\n",
    "\n",
    "# Now we effectively have xi_{ls}(rp=1, Pi(z_s); z_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boost-1, sample a= 0.0316631727836\n",
      "Boost-1, sample b = -1.47902991291e-07\n",
      "Boost-1, sample assoc = 0.758782906799\n"
     ]
    }
   ],
   "source": [
    "# Okay, now we do the required integrals:\n",
    "# Define the z_ph vectors for the three subsamples we are about:\n",
    "lenzph = 10000\n",
    "z_a = scipy.linspace(zeff, zeff +deltaz, lenzph)\n",
    "z_b = scipy.linspace(zeff+deltaz, zphmax, lenzph)\n",
    "# For the \"assoc\" sample we need to get the z-edges\n",
    "zasc_min = z_of_chi(chi_eff - close_cut)\n",
    "zasc_max = z_of_chi(chi_eff + close_cut)\n",
    "z_asc = scipy.linspace(zasc_min, zasc_max, lenzph)\n",
    "\n",
    "# Get dNdz\n",
    "dNdz = get_NofZ_unnormed(dNdzpar, dNdztype, z_Pi)\n",
    "\n",
    "# Do the integrals in spec-z\n",
    "specint_num_a = np.zeros(lenzph); specint_num_b = np.zeros(lenzph); specint_num_asc = np.zeros(lenzph)\n",
    "specint_denom_a = np.zeros(lenzph); specint_denom_b = np.zeros(lenzph); specint_denom_asc = np.zeros(lenzph)\n",
    "for i in range(0, lenzph):\n",
    "    specint_num_a[i] = scipy.integrate.simps(dNdz * p_z(z_a[i], z_Pi, pzpar, pztype) * xi_ofPi, z_Pi)\n",
    "    specint_num_b[i] = scipy.integrate.simps(dNdz * p_z(z_b[i], z_Pi, pzpar, pztype)* xi_ofPi, z_Pi)\n",
    "    specint_num_asc[i] = scipy.integrate.simps(dNdz * p_z(z_asc[i], z_Pi, pzpar, pztype) * xi_ofPi, z_Pi)\n",
    "    \n",
    "    specint_denom_a[i] = scipy.integrate.simps(dNdz * p_z(z_a[i], z_Pi, pzpar, pztype), z_Pi)\n",
    "    specint_denom_b[i] = scipy.integrate.simps(dNdz * p_z(z_b[i], z_Pi, pzpar, pztype), z_Pi)\n",
    "    specint_denom_asc[i] = scipy.integrate.simps(dNdz * p_z(z_asc[i], z_Pi, pzpar, pztype), z_Pi)\n",
    "    \n",
    "# Now do the integrals in photo-z\n",
    "w_a = weights(erms,z_a, zeff)\n",
    "w_b = weights(erms,z_b, zeff)\n",
    "w_asc = weights(erms,z_asc, zeff)\n",
    "\n",
    "B_min_1_a = scipy.integrate.simps(w_a * specint_num_a, z_a) / scipy.integrate.simps(w_a* specint_denom_a, z_a)\n",
    "B_min_1_b = scipy.integrate.simps(w_b * specint_num_b, z_b) / scipy.integrate.simps(w_b* specint_denom_b, z_b)\n",
    "B_min_1_asc = scipy.integrate.simps(w_asc*specint_num_asc, z_asc) / scipy.integrate.simps(w_asc* specint_denom_asc, z_asc)\n",
    "\n",
    "print \"Boost-1, sample a=\", B_min_1_a\n",
    "print \"Boost-1, sample b =\", B_min_1_b\n",
    "print \"Boost-1, sample assoc =\", B_min_1_asc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
