{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/halo_table_cache.py:12: UserWarning: Some of the functionality of the HaloTableCache classrequires h5py to be installed.\n",
      "  warn(\"Some of the functionality of the HaloTableCache class\"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/user_supplied_ptcl_catalog.py:13: UserWarning: Most of the functionality of the sim_manager sub-package requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda\n",
      "  warn(\"Most of the functionality of the sim_manager \"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/download_manager.py:39: UserWarning: Some of the functionality of the DownloadManager requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda\n",
      "  warn(\"Some of the functionality of the DownloadManager requires h5py to be installed,\\n\"\n",
      "/usr/local/lib/python2.7/dist-packages/halotools/sim_manager/cached_halo_catalog.py:15: UserWarning: Most of the functionality of the sim_manager sub-package requires h5py to be installed,\n",
      "which can be accomplished either with pip or conda. \n",
      "  warn(\"Most of the functionality of the \"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shared_functions_wlp_wls as shared\n",
    "import scipy.integrate\n",
    "import pyccl as ccl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SURVEY = 'SDSS'\n",
    "if (SURVEY=='SDSS'):\n",
    "    import params as pa\n",
    "elif (SURVEY=='LSST_DESI'):\n",
    "    import params_LSST_DESI as pa\n",
    "else:\n",
    "    print \"We don't have support for that survey yet; exiting.\"\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: see how well we reproduce the upper panels of Figure 6 from Zu & Mandelbaum 2015 ($w_{gg}$ for different stellar mass bins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize the cosmology\n",
    "OmM = pa.OmC_s + pa.OmB_s; OmB=pa.OmB_s; h0 = pa.HH0_s / 100.; sigma80=pa.sigma8_s; n_s0 = pa.n_s_s;\n",
    "\n",
    "p = ccl.Parameters(Omega_c = OmM-OmB, Omega_b = OmB, h = h0, sigma8=sigma80, n_s=n_s0)\n",
    "cosmo = ccl.Cosmology(p)\n",
    "\n",
    "rho_crit = 3. * 10**10 * pa.mperMpc / (8. * np.pi * pa.Gnewt * pa.Msun)  # Msol h^2 / Mpc^3, for use with M in Msol / h (comoving distances)\n",
    "rho_m = (OmM) * rho_crit # units of Msol h^2 / Mpc^3 (comoving distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define stellar mass bin limits and z's of bins:\n",
    "Mslow = np.asarray([8.5, 9.4, 9.8, 10.2, 10.6, 11.0, 11.2, 11.4, 12.])\n",
    "z = np.asarray([0.02, 0.04, 0.05, 0.08, 0.12, 0.15, 0.17, 0.19])\n",
    "\n",
    "# Define a halo mass range\n",
    "lgMh = np.linspace(10., 15., 30)\n",
    "Mh = 10**(lgMh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At each redshift get the halo mass function and halo bias:\n",
    "HMF = [0]*len(z); bh = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    HMF[zi]= ccl.massfunction.massfunc(cosmo, Mh / h0, 1./ (1. + z[zi]), odelta=200.) / h0**3\n",
    "    bh[zi] = ccl.massfunction.halo_bias(cosmo, Mh / h0, 1./(1.+z[zi]), odelta=200.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get $<N_{\\rm sat}>$ and $<N_{\\rm cen}>$ with $M_*$ threshold of each stellar mass bin edge and subtract appropriately to get it in the stellar mass bins plotted in Figure 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsat_thresh = [0]*len(Mslow)\n",
    "Ncen_thresh = [0]*len(Mslow)\n",
    "for mi in range(0,len(Mslow)):\n",
    "    Nsat_thresh[mi] = shared.get_Nsat_Zu(Mh, 10**Mslow[mi], 'tot', 'SDSS')\n",
    "    Ncen_thresh[mi] = shared.get_Ncen_Zu(Mh, 10**Mslow[mi], 'SDSS')\n",
    "    \n",
    "Nsat_bin = [0] *(len(Mslow) - 1)\n",
    "Ncen_bin = [0] *(len(Mslow) - 1)\n",
    "for bi in range(0, len(Mslow)-1):\n",
    "    Nsat_bin[bi] = Nsat_thresh[bi] - Nsat_thresh[bi+1]\n",
    "    Ncen_bin[bi] = Ncen_thresh[bi] - Ncen_thresh[bi+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each bin get the 1-halo term of the power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First need to get the total number density\n",
    "nbar = np.zeros(len(z))\n",
    "for zi in range(0,len(z)):\n",
    "    nbar[zi] = scipy.integrate.simps(HMF[zi] * (Ncen_bin[zi] + Nsat_bin[zi]), np.log10(Mh / h0))\n",
    "\n",
    "# Get the pair terms for each bin\n",
    "Ncensat_bin = [0] * (len(Mslow)-1)\n",
    "Nsatsat_bin = [0] * (len(Mslow)-1)\n",
    "for bi in range(0,len(Mslow)-1):\n",
    "    Ncensat_bin[bi] = Ncen_bin[bi] * Nsat_bin[bi]\n",
    "    # For the sat-sat case have to make sure we don't accidentally set negative\n",
    "    Nsatsat_bin[bi]= np.zeros(len(Mh))\n",
    "    for mi in range(0,len(Mh)):\n",
    "        if (Nsat_bin[bi][mi]>1.0):\n",
    "            Nsatsat_bin[bi][mi] = Nsat_bin[bi][mi] * (Nsat_bin[bi][mi] -1.)\n",
    "        else:\n",
    "            Nsatsat_bin[bi][mi] = 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Fourier transformed NFW\n",
    "logkmin = -6; kpts =40000; logkmax = 5; \n",
    "kvec_FT = np.logspace(logkmin, logkmax, kpts)\n",
    "# Actually we will use a downsampled version of this:\n",
    "k = np.logspace(np.log10(kvec_FT[0]), np.log10(kvec_FT[-1]), 40)\n",
    "y = shared.gety_ldm(Mh, k, 'SDSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the 1-halo power spectrum in each bin\n",
    "Pkgg_1h = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    Pkgg_1h[zi] = np.zeros(len(k))\n",
    "    for ki in range(0,len(k)):\n",
    "        Pkgg_1h[zi][ki] = scipy.integrate.simps(HMF[zi] * (Ncensat_bin[zi]*y[ki, :] + Nsatsat_bin[zi]*y[ki, :]**2), np.log10(Mh /h0)) / nbar[zi]**2 \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the 2halo power spectrum in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the linear power spectrum from CCL in each bin\n",
    "Pklin = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    # CCL uses units without little-h. Convert to little-h units.\n",
    "    Pklin[zi] = ccl.power.linear_matter_power(cosmo, k * h0, 1. / (1. + z[zi])) * h0**3\n",
    "\n",
    "# Get the 2-halo power spectrum in each bin\n",
    "Pkgg_2h = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    Pkgg_2h[zi] = np.zeros(len(k))\n",
    "    for ki in range(0,len(k)):\n",
    "        Pkgg_2h[zi][ki] = (scipy.integrate.simps(HMF[zi] * bh[zi] * y[ki, :] * (Ncen_bin[zi] + Nsat_bin[zi]), np.log10(Mh /h0)) / nbar[zi])**2 * Pklin[zi][ki]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine 1 and 2 halo terms and output to file for each bin so we can Fourier transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pgg_tot = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    Pgg_tot[zi]=np.zeros(len(k))\n",
    "    for ki in range(0,len(k)):\n",
    "        if k[ki]>10**(-2):\n",
    "            Pgg_tot[zi][ki] = Pkgg_2h[zi][ki] + Pkgg_1h[zi][ki]\n",
    "        else:\n",
    "            Pgg_tot[zi][ki] = Pkgg_2h[zi][ki]\n",
    "    \n",
    "    # This needs to be interms of the more well-sampled k vector\n",
    "    interp_in_k = scipy.interpolate.interp1d(np.log(k), np.log(Pgg_tot[zi]))\n",
    "    full_Pgg = np.exp(interp_in_k(np.log(kvec_FT)))\n",
    "    \n",
    "    save_P1h2h = np.column_stack((kvec_FT, full_Pgg))\n",
    "    np.savetxt('./txtfiles/halofit_Pk/Pgg_compFig6_bin='+str(zi)+'.txt', save_P1h2h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import $\\xi_{gg}(r)$ as Fourier transformed using FFTlog from our power spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xigg = [0]*len(z)\n",
    "r = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    r[zi], xigg[zi] = np.loadtxt('./txtfiles/halofit_xi/xigg_compFig6_bin='+str(zi)+'.txt', unpack=True)\n",
    "    for ri in range(0,len(r[zi])):\n",
    "        if xigg[zi][ri]<10**(-12):\n",
    "            xigg[zi][ri]=10**(-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project to get $w_{gg}$ for each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each bin interpolate xi in r\n",
    "interp_xi = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    interp_xi[zi] = scipy.interpolate.interp1d(np.log(r[zi]), np.log(xigg[zi]))\n",
    "    \n",
    "rp = np.logspace(-2, 2, 100)\n",
    "Pi = np.logspace(-5, np.log10(80.), 1000) # use the same projection length as Reid & Spergel 2008\n",
    "\n",
    "# For each bin get xi in terms of rp and Pi\n",
    "logxi_2d = [0] * len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    logxi_2d[zi] = np.zeros((len(rp), len(Pi)))\n",
    "    for ri in range(0,len(rp)):\n",
    "        for pi in range(0,len(Pi)):\n",
    "            r_2d = np.sqrt( rp[ri]**2 + Pi[pi]**2 )\n",
    "            logxi_2d[zi][ri, pi] = interp_xi[zi](np.log(r_2d))\n",
    "\n",
    "# Now project at each rp and in each bin            \n",
    "wgg = [0]*len(z)\n",
    "for zi in range(0,len(z)):\n",
    "    wgg[zi] = np.zeros(len(rp))\n",
    "    for ri in range(0,len(rp)):\n",
    "        wgg[zi][ri] = 2.*scipy.integrate.simps(np.exp(logxi_2d[zi][ri,:]), Pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now output what we have calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.loglog(rp, wgg[0], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 8.5-9.4$')\n",
    "plt.savefig('./plots/wgg_bin=0.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[1], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 9.4-9.8$')\n",
    "plt.savefig('./plots/wgg_bin=1.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[2], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 9.8-10.2$')\n",
    "plt.savefig('./plots/wgg_bin=2.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[3], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 10.2-10.6$')\n",
    "plt.savefig('./plots/wgg_bin=3.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[4], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 10.6-11.0$')\n",
    "plt.savefig('./plots/wgg_bin=4.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[5], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 11.0-11.2$')\n",
    "plt.savefig('./plots/wgg_bin=5.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[6], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 11.2-11.4$')\n",
    "plt.savefig('./plots/wgg_bin=6.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(rp, wgg[7], 'b+')\n",
    "plt.ylim(5,10000)\n",
    "plt.xlim(0.03,25)\n",
    "plt.ylabel('$w_p$')\n",
    "plt.xlabel('$r_p$')\n",
    "plt.title('$w_{gg}, M_* = 11.4-12$')\n",
    "plt.savefig('./plots/wgg_bin=7.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Okay so that's all basically correct, up to small factors, which I think are probably explainable by me guessing at redshifts for each bin. That's also not too surprising, given these quantities are largely related to large scales and large scales are not the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
